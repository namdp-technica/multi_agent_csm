#!/usr/bin/env python3
"""
Test script Ä‘á»ƒ kiá»ƒm tra VLM cÃ³ nháº­n Ä‘Æ°á»£c áº£nh tá»« folder tools_results khÃ´ng
"""

import os
import base64
import asyncio
from google.adk.models.lite_llm import LiteLlm
from google.adk.agents import LlmAgent
from google.adk.core import InMemorySessionService, Runner
import google.genai.types as types

# Config giá»‘ng nhÆ° trong agent.py
os.environ['OPENAI_API_KEY'] = "sk-fake-key-for-local-model"
api_base_url = "http://85.167.195.195:34751/v1"

def load_image_as_base64(image_path):
    """Load áº£nh vÃ  convert sang base64"""
    try:
        with open(image_path, 'rb') as f:
            image_data = f.read()
            return base64.b64encode(image_data).decode('utf-8')
    except Exception as e:
        print(f"âŒ Error loading image {image_path}: {e}")
        return None

def get_available_images():
    """Láº¥y danh sÃ¡ch áº£nh cÃ³ sáºµn trong tools_results"""
    tools_results_dir = "tools_results"
    if not os.path.exists(tools_results_dir):
        print(f"âŒ Directory {tools_results_dir} not found")
        return []
    
    images = [f for f in os.listdir(tools_results_dir) if f.endswith('.png')]
    return sorted(images)

async def test_vlm_with_image(image_path, question="Describe what you see in this image"):
    """Test VLM vá»›i má»™t áº£nh cá»¥ thá»ƒ"""
    print(f"\nğŸ§ª Testing VLM with image: {image_path}")
    print(f"ğŸ“ Question: {question}")
    print("="*80)
    
    # Load áº£nh
    base64_image = load_image_as_base64(image_path)
    if not base64_image:
        return
    
    # Táº¡o VLM agent
    vlm_model = LiteLlm(
        model="hosted_vllm/AIDC-AI/Ovis2-4B", 
        api_base=api_base_url,
        api_key="sk-fake-key-for-local-model"
    )
    
    vlm_agent = LlmAgent(
        name="TestVLMAgent",
        model=vlm_model,
        description="Test VLM Agent - PhÃ¢n tÃ­ch áº£nh",
        instruction="""
Báº¡n lÃ  VLM Agent. Nhiá»‡m vá»¥ cá»§a báº¡n:

1. Nháº­n cÃ¢u há»i vÃ  thÃ´ng tin áº£nh tá»« input
2. PhÃ¢n tÃ­ch áº£nh Ä‘Æ°á»£c cung cáº¥p vÃ  tráº£ lá»i cÃ¢u há»i

QUY Táº®C QUAN TRá»ŒNG:
- CHá»ˆ tráº£ lá»i náº¿u ná»™i dung áº£nh cÃ³ liÃªn quan trá»±c tiáº¿p Ä‘áº¿n cÃ¢u há»i
- Náº¿u áº£nh KHÃ”NG liÃªn quan Ä‘áº¿n cÃ¢u há»i, hÃ£y tráº£ lá»i: "TÃ´i khÃ´ng biáº¿t"
- Náº¿u áº£nh cÃ³ liÃªn quan, hÃ£y tráº£ lá»i ngáº¯n gá»n, chÃ­nh xÃ¡c dá»±a trÃªn ná»™i dung áº£nh
- KhÃ´ng bá»‹a Ä‘áº·t thÃ´ng tin khÃ´ng cÃ³ trong áº£nh
- MÃ´ táº£ chi tiáº¿t nhá»¯ng gÃ¬ báº¡n tháº¥y trong áº£nh
"""
    )
    
    # Táº¡o session vÃ  runner
    session_service = InMemorySessionService()
    runner = Runner(vlm_agent, session_service)
    session = await session_service.create_session()
    
    try:
        # Táº¡o content vá»›i text vÃ  image
        image_part = types.Part(
            inline_data=types.Blob(
                mime_type="image/png",
                data=base64_image
            )
        )
        
        text_part = types.Part(text=f"""
User query: {question}
Image ID: {os.path.basename(image_path)}
Image description: Test image from tools_results folder

Please analyze this image and answer the user's question. Be detailed about what you see.
""")
        
        content = types.Content(
            parts=[text_part, image_part],
            role="user"
        )
        
        print("ğŸ“¤ Sending request to VLM...")
        print(f"   - Image size: {len(base64_image)} chars (base64)")
        print(f"   - Model: hosted_vllm/AIDC-AI/Ovis2-4B")
        print(f"   - API Base: {api_base_url}")
        
        # Gá»­i request
        event_count = 0
        async for event in runner.run_async(session, new_message=content):
            event_count += 1
            print(f"\nğŸ“¥ Event #{event_count}:")
            
            if hasattr(event, 'content') and event.content:
                if hasattr(event.content, 'parts') and event.content.parts:
                    for part in event.content.parts:
                        if hasattr(part, 'text') and part.text:
                            print(f"ğŸ’¬ VLM Response: {part.text}")
                            return part.text
            
            # Giá»›i háº¡n sá»‘ events Ä‘á»ƒ trÃ¡nh loop vÃ´ táº­n
            if event_count >= 5:
                print("âš ï¸  Reached max events limit")
                break
        
        print("âŒ No valid response received")
        
    except Exception as e:
        print(f"âŒ Error during VLM processing: {e}")
        import traceback
        traceback.print_exc()

async def main():
    """Main test function"""
    print("ğŸš€ VLM Image Test Starting...")
    print("="*80)
    
    # Láº¥y danh sÃ¡ch áº£nh
    images = get_available_images()
    if not images:
        print("âŒ No images found in tools_results directory")
        return
    
    print(f"ğŸ“ Found {len(images)} images in tools_results:")
    for i, img in enumerate(images[:5]):  # Show first 5
        print(f"   {i+1}. {img}")
    if len(images) > 5:
        print(f"   ... and {len(images) - 5} more")
    
    # Test vá»›i áº£nh Ä‘áº§u tiÃªn
    test_image = os.path.join("tools_results", images[0])
    
    # Test cases
    test_cases = [
        "Describe what you see in this image in detail",
        "æ¸©åº¦å·®è·é‡ã®è¨˜å·ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
        "What symbols or text can you see in this image?",
        "ã“ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã«ã¯ä½•ãŒè¦‹ãˆã¾ã™ã‹ï¼Ÿ"
    ]
    
    for question in test_cases:
        await test_vlm_with_image(test_image, question)
        print("\n" + "="*80)
    
    print("âœ… VLM Image Test Completed!")

if __name__ == "__main__":
    asyncio.run(main())